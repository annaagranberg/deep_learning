{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07fb8c1e-72c4-47c7-a243-5ad2de9d5dc9",
   "metadata": {},
   "source": [
    "# TNM112 -- Lab 3\n",
    "Instructions about the different tasks are specified in this notebook. However, for more details, please see the PDF with lab instructions. Also see the lab report template for information on how to report your results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90918b35-22b9-4d79-86b5-ff59405c91c0",
   "metadata": {},
   "source": [
    "### Data generation\n",
    "Look through the \"data_generator.py\" code to understand how the dataset is generated and plotted.\n",
    "\n",
    "The \"importlib\" library is used to enable reloading of a library each time the cell is executed (so that changes to the imported script will be visible without restarting the notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93532893-6c86-47d9-92c7-05c8e2378e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data specification:\n",
      "\tDataset type:           cifar10\n",
      "\tNumber of classes:      10\n",
      "\tNumber of channels:     3\n",
      "\tTraining data shape:    (3000, 32, 32, 3)\n",
      "\tValidation data shape:  (5000, 32, 32, 3)\n",
      "\tTest data shape:        (10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "import util\n",
    "import data_generator\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = data_generator.DataGenerator()\n",
    "\n",
    "data.generate(dataset='cifar10', N_train=3000, N_valid=0.1)\n",
    "#data.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edfde8e-f191-427f-bb3d-f62b6271a74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "import util\n",
    "import data_generator\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import img_as_float\n",
    "from tensorflow.keras import layers, models\n",
    "import tensorflow as tf\n",
    "\n",
    "def colorization_cnn(input_shape):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Encoder\n",
    "    conv1 = layers.Conv2D(64, (3, 3), activation=None, padding=\"same\")(inputs)\n",
    "    #x = layers.BatchNormalization()(conv1)\n",
    "    #x = layers.ReLU()(x)  # Apply ReLU after BatchNormalization\n",
    "    #pool1 = layers.MaxPooling2D((2, 2), padding=\"same\")(conv1)\n",
    "   \n",
    "    conv2 = layers.Conv2D(128, (3, 3), activation=None, padding=\"same\")(conv1)\n",
    "    #x = layers.BatchNormalization()(conv2)\n",
    "    #x = layers.ReLU()(x)\n",
    "    #pool2 = layers.MaxPooling2D((2, 2), padding=\"same\")(conv2)\n",
    "   \n",
    "    conv3 = layers.Conv2D(256, (3, 3), activation=None, padding=\"same\")(conv2)  # Additional layer\n",
    "    #x = layers.BatchNormalization()(conv3)\n",
    "    #x = layers.ReLU()(x)\n",
    "    #pool3 = layers.MaxPooling2D((2, 2), padding=\"same\")(conv3)\n",
    "   \n",
    "    # Bottleneck\n",
    "    bottleneck = layers.Conv2D(512, (3, 3), activation=None, padding=\"same\")(conv3)  # Increased depth\n",
    "    #x = layers.BatchNormalization()(bottleneck)\n",
    "    #x = layers.ReLU()(x)\n",
    "   \n",
    "    # Decoder with skip-connections\n",
    "    #up3 = layers.UpSampling2D((2, 2))(bottleneck)\n",
    "    #concat3 = layers.concatenate([up3, conv3])\n",
    "    conv4 = layers.Conv2D(256, (3, 3), activation=None, padding=\"same\")(bottleneck)\n",
    "    #x = layers.BatchNormalization()(conv4)\n",
    "    #x = layers.ReLU()(x)\n",
    "   \n",
    "    #up2 = layers.UpSampling2D((2, 2))(conv4)\n",
    "    #concat2 = layers.concatenate([up2, conv2])\n",
    "    conv5 = layers.Conv2D(128, (3, 3), activation=None, padding=\"same\")(conv4)\n",
    "    #x = layers.BatchNormalization()(conv5)\n",
    "    #x = layers.ReLU()(x)\n",
    "   \n",
    "    #up1 = layers.UpSampling2D((2, 2))(conv5)\n",
    "    #concat1 = layers.concatenate([up1, conv1])\n",
    "    conv6 = layers.Conv2D(64, (3, 3), activation=None, padding=\"same\")(conv5)\n",
    "    #x = layers.BatchNormalization()(conv6)\n",
    "    #x = layers.ReLU()(x)\n",
    "   \n",
    "    outputs = layers.Conv2D(3, (3, 3), activation=\"sigmoid\", padding=\"same\")(conv6)  # Final output for colorization\n",
    "   \n",
    "    model = models.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 32\n",
    "\n",
    "input_shape = data.x_train_gray.shape[1:] \n",
    "\n",
    "model = colorization_cnn(input_shape)\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "model.summary()\n",
    "\n",
    "log = model.fit(data.x_train_gray, data.x_train, batch_size=batch_size, epochs=epochs,\n",
    "                validation_data=(data.x_valid_gray, data.x_valid), validation_freq=1)\n",
    "\n",
    "util.evaluate(model, data)\n",
    "\n",
    "# Generate a random sample for evaluation\n",
    "sample_idx = np.random.randint(len(data.x_valid))\n",
    "grayscale_input = data.x_valid_gray[sample_idx]\n",
    "predicted_color = model.predict(np.expand_dims(grayscale_input, axis=0))[0]\n",
    "real_color_image = data.x_valid[sample_idx] \n",
    "\n",
    "# Convert predicted and original images to float\n",
    "predicted_color = img_as_float(predicted_color)\n",
    "real_color_image = img_as_float(real_color_image)\n",
    "\n",
    "print(f\"Predicted image shape: {predicted_color.shape}\")\n",
    "print(f\"Real image shape: {real_color_image.shape}\")\n",
    "\n",
    "# Compute metrics\n",
    "ssim_score = util.compute_ssim(predicted_color, real_color_image)\n",
    "snr_score = util.compute_snr(predicted_color, real_color_image)\n",
    "scielab_score = util.compute_scielab(predicted_color, real_color_image)\n",
    "\n",
    "print(f\"SSIM: {ssim_score:.4f}\")\n",
    "print(f\"SNR: {snr_score:.2f} dB\")\n",
    "print(f\"SCIELAB: {scielab_score:.4f}\")\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Grayscale input\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(grayscale_input.squeeze(), cmap='gray')\n",
    "plt.title(\"Input (Grayscale)\")\n",
    "\n",
    "# Predicted Colorized Image\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(predicted_color)\n",
    "plt.title(f\"Predicted (Colorized)\\nSSIM: {ssim_score:.4f}\")\n",
    "\n",
    "# Original (True Color) Image\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(real_color_image)\n",
    "plt.title(\"Original (True Color)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65618848-92b0-4218-8937-39707528b0c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daab5599-9a97-4b22-a090-bb8e5aa3c3d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
